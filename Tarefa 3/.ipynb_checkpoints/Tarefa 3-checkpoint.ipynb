{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Universidade Federal de Santa Catarina<br>\n",
    "Departamento de Engenharia Elétrica e Eletrônica<br>\n",
    "EEL7514/EEL7513 - Introdução ao Aprendizado de Máquina\n",
    "$\\newcommand{\\bX}{\\mathbf{X}}$\n",
    "$\\newcommand{\\bw}{\\mathbf{w}}$\n",
    "$\\newcommand{\\by}{\\mathbf{y}}$\n",
    "$\\newcommand{\\bx}{\\mathbf{x}}$\n",
    "$\\newcommand{\\RR}{\\mathbb{R}}$\n",
    "\n",
    "## Aluno:  Luiz Eduardo Hupalo 17203887\n",
    "\n",
    "\n",
    "# Exercício 3: Regressão Linear (II)\n",
    "\n",
    "Neste exercício você irá explorar métodos de otimização numérica para treinar um modelo de regressão linear. Em particular, você irá implementar o método do gradiente e analisar sua convergência. Além disso, você irá investigar o efeito da normalização de atributos no comportamento do método. Finalmente, você irá investigar a aplicação de regressão linear em um conjunto de dados real."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conjunto de dados #1\n",
    "\n",
    "Inicialmente, utilizaremos o mesmo conjunto de dados do exercício anterior, exceto por uma escala diferente em $x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def gen_data(n_samples, x_scale=[0,1], noise=0.5):\n",
    "    '''Generate univariate regression dataset'''\n",
    "    x = np.sort(np.random.rand(n_samples))\n",
    "    y = 6*(-1/6 + x + (x > 1/3)*(2/3-2*x) + (x > 2/3)*(2*x-4/3)) + noise*np.random.randn(n_samples)\n",
    "    x = x_scale[0] + (x_scale[1]-x_scale[0])*x\n",
    "    X = x.reshape(-1,1)\n",
    "    return X, y\n",
    "\n",
    "def plot_data(X, y):\n",
    "    '''Plot univariate regression dataset'''\n",
    "    assert len(X.shape) == 2 and len(y.shape) == 1\n",
    "    plt.plot(X[:,0],y,'b.'); plt.xlabel('x'); plt.ylabel('y');\n",
    "    return\n",
    "\n",
    "def plot_prediction(model, X, y, n_points=100):\n",
    "    '''Plot dataset and predictions for a univariate regression model'''\n",
    "    plot_data(X,y)\n",
    "    if n_points is not None:\n",
    "        xx = np.linspace(X.min(),X.max(),n_points)\n",
    "        yy = model.predict(xx.reshape(-1,1))\n",
    "        plt.plot(xx,yy,'r-')\n",
    "    y_pred = model.predict(X)\n",
    "    plt.plot(X[:,0],y_pred,'r.')\n",
    "    plt.legend(['True', 'Predicted'])\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O conjunto de dados pode ser gerado e visualizado pelos comandos abaixo (observe a nova escala)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 1) (30,)\n",
      "(1000, 1) (1000,)\n",
      "(1000, 1) (1000,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(2019*2)\n",
    "X, y = gen_data(n_samples=30, x_scale=[0,4])\n",
    "X_val, y_val = gen_data(n_samples=1000, x_scale=[0,4])\n",
    "X_test, y_test = gen_data(n_samples=1000, x_scale=[0,4])\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "# Plot only the training data!\n",
    "plot_data(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Método do gradiente\n",
    "\n",
    "Resgate a classe do modelo que você implementou no exercício anterior. Primeiramente, iremos reorganizá-la para torná-la **parcialmente** compatível com a biblioteca `sklearn`, bem como permitir um método de treinamento alternativo.\n",
    "\n",
    "- Utilize a classe abaixo, substituindo na função `__fit_ne` a sua função `fit` implementada anteriormente.\n",
    "- Note que a função `add_powers` foi eliminada (bem como o argumento `d` da inicialização do modelo), sendo substituída pela função `add_ones` (que simplesmente adiciona uma coluna de 1's). Ou seja, nosso modelo deve implementar puramente uma regressão linear (com regularização L2), sem atributos adicionais. Caso desejemos atributos polinomiais, poderemos usar a classe `PolynomialFeatures` do sklearn. A única vantagem do nosso modelo de regressão próprio em relação ao `Ridge` é permitir utilizar um método de treinamento diferente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    # Linear regression with L2 regularization\n",
    "    def __init__(self, lamb=0, solver='ne', lr=1, maxiter=1000, tol=1e-5):\n",
    "        # Initialization\n",
    "        self.lamb = lamb\n",
    "        self.solver = solver\n",
    "        self.lr = lr\n",
    "        self.maxiter = maxiter\n",
    "        self.tol = tol\n",
    "        return\n",
    "    \n",
    "    def __add_ones(self, X):\n",
    "        # Add column of ones\n",
    "        X_new = np.c_[np.ones(X.shape[0]), X]\n",
    "        return X_new\n",
    "    \n",
    "    def __fit_ne(self, X, y):\n",
    "        # Fit by normal equation\n",
    "        X = self.__add_ones(X)\n",
    "        L = 1;\n",
    "        assert np.linalg.matrix_rank(X.T @ X + self.lamb*L) == X.shape[1], 'Singular matrix'\n",
    "        self.w = (np.linalg.inv((X.T @ X) + self.lamb*L) @ X.T) * y\n",
    "        return\n",
    "\n",
    "    def __fit_gd(self, X, y):\n",
    "        # Fit by gradient descent\n",
    "        \n",
    "        self.w = np.zeros(2,1)\n",
    "        self.w.reshape(-1,1)\n",
    "        \n",
    "        for i in range(self.maxiter)\n",
    "            \n",
    "            w_new = self.w - self.lr * 2/len(X)*X.T*(X*self.w - y)\n",
    "            \n",
    "            if numpy.linalg.norm(w_new) < self.tol:\n",
    "                break\n",
    "        \n",
    "        return\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if self.solver == 'gd':\n",
    "            self.__fit_gd(X, y)\n",
    "        elif self.solver == 'ne':\n",
    "            self.__fit_ne(X, y)\n",
    "        else:\n",
    "            raise RuntimeError('Unknown solver')\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = self.__add_ones(X)\n",
    "        y_pred = self.w.T * X\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mova a função `mse` para fora da classe, caso contrário não poderemos acessá-la dentro de um `Pipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(model, X, y):\n",
    "    return mean_squared_error(y,model.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Complete a função `__fit_gd` implementando o método do gradiente. Utilize os parâmetros `self.lr` (taxa de aprendizado), `self.maxiter` (número máximo de iterações) e `self.tol` (critério de parada para a norma do gradiente). Além de calcular `self.w`, sua função deve criar também uma lista, `self.J_history`, contendo os valores da função custo (regularizada) a cada iteração, a qual será usada para monitorar o treinamento e analisar a taxa de aprendizado.\n",
    "- Treine o modelo (usando `solver='gd'`), trace o gráfico de `J_history` e escolha uma boa taxa de aprendizado. Quantas iterações foram necessárias para convergência?\n",
    "- Calcule o MSE de treinamento e de validação e compare-os com os obtidos pela solução analítica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adicionando atributos\n",
    "\n",
    "- Adicione atributos polinomiais de graus `d=2` e `d=3`, usando o transformador `PolynomialFeatures` e a função `make_pipeline`. Verifique a dificuldade de convergência. Por que isso ocorre? Foi necessário alterar a taxa de aprendizado? E o número máximo de iterações?\n",
    "- Assim como anteriormente, compare o MSE obtido com a da solução analítica.\n",
    "- Para fins de análise, calcule a hessiana da função custo (dentro do treinamento) e utilize a função `np.linalg.cond()` para estimar o grau de condicionamento da matriz.\n",
    "\n",
    "#### Dica\n",
    "\n",
    "- Não há necessidade de incluir o termo constante nos atributos adicionados, uma vez que o modelo já implementa a adição de coluna de 1's. Assim, utilize `PolynomialFeatures(d,include_bias=False)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escalonamento de atributos\n",
    "\n",
    "- Implemente a normalização (escalonamento) de atributos conforme vista em sala, a qual consiste de:\n",
    " - Subtração da média do atributo, para que passe a ter média nula\n",
    " - Divisão pelo desvio padrão do atributo, para que passe a ter variância unitária\n",
    " \n",
    "Esse tipo de normalização também é chamado em alguns contextos de padronização (_standardization_), no sentido de resultar na mesma média (0) e variância (1) de uma variável aleatória gaussiana padrão (_standard_), em contraste com outros tipos de normalização (por exemplo, reescalonamento para a escala [0,1]).\n",
    "\n",
    "- Para isso, complete a classe abaixo. Caso deseje confirmar se sua implementação está correta, compare com o transformador `StandardScaler` do módulo `sklearn.preprocessing`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyStandardScalar():\n",
    "    def fit(self, X, y=None):\n",
    "        # Compute and store scaler parameters\n",
    "        \n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        # Scale features\n",
    "        \n",
    "        return X_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Após implementar corretamente, verifique que seu escalonador funciona corretamente em um pipeline do `sklearn`. Em seguida, você pode ignorar sua implementação e passar a usar o `StandardScaler`.\n",
    "- Refaça os mesmos passos da seção anterior e compare os resultados e o comportamento do algoritmo. Explique.\n",
    "- (OPCIONAL) Experimente outros escalonadores do `sklearn`, como `MinMaxScaler` e `MaxAbsScaler`, e compare o desempenho obtido.\n",
    "\n",
    "#### Dicas\n",
    "\n",
    "- Funções úteis:\n",
    "\n",
    "```python\n",
    "np.mean(axis=0), np.std(axis=0)\n",
    "```\n",
    "\n",
    "- Revise as propriedades de broadcasting do NumPy, em particular em operações envolvendo matrizes e arrays 1D.\n",
    "- Para depurar possíveis erros, lembre-se de verificar o `shape` dos arrays envolvidos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ainda mais atributos\n",
    "\n",
    "- Adicione atributos polinomiais de grau ainda maior. O que você observa?\n",
    "- Você recomendaria o método do gradiente para um problema desse tipo? Ou seria melhor usar um método de segunda ordem? Explique.\n",
    "- Ao invés de adicionar inúmeros atributos polinomiais, seja criativo: utilize poucos atributos que aproximem melhor o conjunto de treinamento. Lembre que você pode introduzir qualquer função que desejar. No `sklearn` isso pode ser feito utilizando a classe abaixo, a qual pode ser integrada em uma *pipeline*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyFeatures():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_new\n",
    "        return X_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conjunto de dados #2\n",
    "\n",
    "O segundo conjunto de dados que usaremos consiste de dados sobre a venda de casas em King County, USA, entre maio de 2014 e maio de 2015. O objetivo é prever o preço de venda a partir de informações sobre a casa. Baixe o arquivo em\n",
    "\n",
    "http://www.kaggle.com/harlfoxem/housesalesprediction/data\n",
    "\n",
    "descompacte-o e salve-o numa subpasta `data`, i.e., o arquivo estará acessível em `data/kc_house_data.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date     price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  7129300520  20141013T000000  221900.0         3       1.00         1180   \n",
       "1  6414100192  20141209T000000  538000.0         3       2.25         2570   \n",
       "2  5631500400  20150225T000000  180000.0         2       1.00          770   \n",
       "3  2487200875  20141209T000000  604000.0         4       3.00         1960   \n",
       "4  1954400510  20150218T000000  510000.0         3       2.00         1680   \n",
       "\n",
       "   sqft_lot  floors  waterfront  view  ...  grade  sqft_above  sqft_basement  \\\n",
       "0      5650     1.0           0     0  ...      7        1180              0   \n",
       "1      7242     2.0           0     0  ...      7        2170            400   \n",
       "2     10000     1.0           0     0  ...      6         770              0   \n",
       "3      5000     1.0           0     0  ...      7        1050            910   \n",
       "4      8080     1.0           0     0  ...      8        1680              0   \n",
       "\n",
       "   yr_built  yr_renovated  zipcode      lat     long  sqft_living15  \\\n",
       "0      1955             0    98178  47.5112 -122.257           1340   \n",
       "1      1951          1991    98125  47.7210 -122.319           1690   \n",
       "2      1933             0    98028  47.7379 -122.233           2720   \n",
       "3      1965             0    98136  47.5208 -122.393           1360   \n",
       "4      1987             0    98074  47.6168 -122.045           1800   \n",
       "\n",
       "   sqft_lot15  \n",
       "0        5650  \n",
       "1        7639  \n",
       "2        8062  \n",
       "3        5000  \n",
       "4        7503  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/kc_house_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como variável de saída, $y$, utilize o **logaritmo** neperiano do preço de venda , `price`, i.e., `np.log(price)`. Desta forma o erro na predição de $y$ será função do erro _relativo_ na predição do preço, evitando dar peso excessivo aos preços mais altos. Como atributos, utilize apenas as 4 colunas após o preço de venda, i.e., `bedrooms`, `bathrooms`, `sqft_living` e `sqft_lot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21560, 4) (21560,)\n"
     ]
    }
   ],
   "source": [
    "# Removing outliers\n",
    "\n",
    "df = df[df['bedrooms']<10]\n",
    "df = df[df['bathrooms']<6]\n",
    "df = df[df['sqft_living']<7000]\n",
    "df = df[df['sqft_lot']<600e3]\n",
    "\n",
    "data = df[['bedrooms','bathrooms','sqft_living','sqft_lot','price']].to_numpy()\n",
    "X = data[:,:4]\n",
    "y = np.log(data[:,4])\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separe o conjunto de dados aleatoriamente em conjuntos de treinamento, validação e teste, nas proporções 60%, 20% e 20%, respectivamente. Para isso, utilize a função `sklearn.model_selection.train_test_split()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "X_train, X_val, y_train, y_val = train_test_split(  , test_size=y_test.shape[0], random_state=0)\n",
    "del(X,y) # just to make sure we will not use them by mistake. Or set X,y = X_train,y_train\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como função perda para o treinamento, utilize o erro quadrático, e, como métrica de avaliação do modelo, utilize a raiz quadrada do erro quadrático médio. Ambos são equivalentes, mas o segundo resulta em valores numa escala mais agradável para análise e mais fácil de interpretar. Para facilitar, utilize a função abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(model, X, y):\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploração dos dados\n",
    "\n",
    "Antes de escolher e começar a treinar um modelo, é útil fazer uma breve exploração dos dados. (Foi dessa exploração inicial que surgiu a ideia, por exemplo, de remover outliers, com aqueles valores específicos.) Para cada atributo, trace o gráfico da variável de saída em função do atributo, sobre o conjunto de treinamento. Observe as escalas das variáveis envolvidas e analise se há alguma dependência aparente entre as variáveis. Intuitivamente, qual atributo parece ser mais preditivo do preço do venda?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressão linear\n",
    "\n",
    "Inicialmente você deve treinar um modelo de regressão linear sem regularização e calcular o RMSE da predição sobre o conjunto de treinamento e sobre o conjunto de validação. Fique à vontade para usar as funções do `sklearn`, não há necessidade de usar o método do gradiente.\n",
    "\n",
    "Você diria que o modelo treinado sofre de underfitting, overfitting ou nenhum dos dois? Explique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aprimorando o modelo\n",
    "\n",
    "Usando o que vimos até agora na disciplina, tente ao máximo melhorar o desempenho do modelo neste conjunto de dados. Use sua criatividade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
